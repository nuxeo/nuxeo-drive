import time
from pathlib import Path
from unittest.mock import patch

from nuxeo.exceptions import Conflict, HTTPError, Unauthorized
from requests import ConnectionError

from nxdrive.constants import ROOT, WINDOWS
from nxdrive.utils import safe_filename

from .. import ensure_no_exception
from . import LocalTest
from .common import OS_STAT_MTIME_RESOLUTION, OneUserNoSync, OneUserTest, TwoUsersTest


class TestSynchronizationDisabled(OneUserNoSync):
    """Test with synchronization features disabled."""

    def test_basic_synchronization(self):
        """Test that nothing will be synced."""

        local = self.local_1
        remote = self.remote_document_client_1
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)

        # The local root is not created
        assert not local.exists("/remote folder")

        # Force its creation to test local changes are not reflected remotely
        local.unlock_ref(local.base_folder)
        local.base_folder.mkdir()
        local.make_folder("/", "local folder")

        # Create a remote document to check that nothing will be locally synced
        remote.make_folder("/", "remote folder")

        # Sync and checks
        self.wait_sync(wait_for_async=True)
        assert not remote.exists("/local folder")
        assert local.exists("/local folder")
        assert not local.exists("/remote folder")


class TestSynchronization(OneUserTest):
    def test_binding_initialization_and_first_sync(self):
        local = self.local_1
        remote = self.remote_document_client_1

        # Create some documents in a Nuxeo workspace and bind this server to a
        # Nuxeo Drive local folder
        docs = self.make_server_tree()

        # The root binding operation does not create the local folder yet.
        assert not local.exists("/")

        # Launch ndrive and check synchronization
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)
        assert local.exists("/")
        assert local.exists("/Folder 1")
        assert local.get_content("/Folder 1/File 1.txt") == b"aaa"
        assert local.exists("/Folder 1/Folder 1.1")
        assert local.get_content("/Folder 1/Folder 1.1/File 2.txt") == b"bbb"
        assert local.exists("/Folder 1/Folder 1.2")
        assert local.get_content("/Folder 1/Folder 1.2/File 3.txt") == b"ccc"
        assert local.exists("/Folder 2")
        # Cannot predict the resolution in advance
        assert remote.get_note(docs["Dupe 1.txt"]) == b"Some content."
        assert remote.get_note(docs["Dupe 2.txt"]) == b"Other content."
        assert local.get_content("/Folder 2/File 4.txt") == b"ddd"
        assert local.get_content("/File 5.txt") == b"eee"

        # Unbind root and resynchronize
        remote.unregister_as_root(self.workspace)

        # Since errors are generated by the deletion events sent
        # by Watchdog for the workspace children under UNIX,
        # don't enforce errors
        self.wait_sync(wait_for_async=True, enforce_errors=WINDOWS)
        assert not local.exists("/")

    def test_binding_synchronization_empty_start(self):
        local = self.local_1
        remote = self.remote_document_client_1

        # Let's create some documents on the server and
        # launch the first synchronization
        docs = self.make_server_tree()
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)

        # We should now be fully synchronized
        file_count, folder_count = self.get_local_child_count(
            self.local_nxdrive_folder_1
        )
        assert folder_count == 5
        assert file_count == 6

        # Wait a bit for file time stamps to increase enough: on OSX HFS+ the
        # file modification time resolution is 1s for instance
        time.sleep(OS_STAT_MTIME_RESOLUTION)

        # Let do some local and remote changes concurrently
        local.delete("/File 5.txt")
        local.update_content("/Folder 1/File 1.txt", b"aaaa")
        local.make_folder("/", "Folder 4")

        # The remote client used in this test is handling paths relative to
        # the 'Nuxeo Drive Test Workspace'
        remote.update(docs["File 2.txt"], properties={"note:note": "bbbb"})
        remote.delete("/Folder 2")
        f3 = remote.make_folder(self.workspace, "Folder 3")
        remote.make_file(f3, "File 6.txt", content=b"ffff")

        # Launch synchronization
        self.wait_sync(wait_for_async=True)

        # We should now be fully synchronized again
        assert not remote.exists("/File 5.txt")
        assert remote.get_note(docs["File 1.txt"]) == b"aaaa"
        assert remote.exists("/Folder 4")

        assert local.get_content("/Folder 1/Folder 1.1/File 2.txt") == b"bbbb"
        # Let's just check remote document hasn't changed
        assert remote.get_note(docs["File 2.txt"]) == b"bbbb"
        assert not local.exists("/Folder 2")
        assert local.exists("/Folder 3")
        assert local.get_content("/Folder 3/File 6.txt") == b"ffff"

    def test_single_quote_escaping(self):
        remote = self.remote_document_client_1
        local = LocalTest(self.local_nxdrive_folder_1)
        dao = self.engine_1.dao

        file = "APPEL D'OFFRES"
        assert dao._escape(file) == "APPEL D''OFFRES"

        remote.unregister_as_root(self.workspace)
        self.engine_1.start()

        with ensure_no_exception():
            remote.make_folder("/", file)
            filename = f"/{file}"

            remote.register_as_root(filename)
            self.wait_sync(wait_for_async=True)
            assert local.exists(filename)

            remote.unregister_as_root(filename)
            self.wait_sync(wait_for_async=True)
            assert not local.exists(filename)

    def test_invalid_credentials(self):
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)

        # Simulate bad responses
        with patch.object(self.engine_1, "remote", new=self.get_bad_remote()):
            self.engine_1.remote.request_token()
            self.engine_1.remote.make_server_call_raise(Unauthorized(message="Mock"))
            self.wait_sync(wait_for_async=True, fail_if_timeout=False)
            assert self.engine_1.is_offline()

            self.engine_1.set_offline(value=False)
            self.engine_1.set_invalid_credentials(value=False)
            self.engine_1.resume()

    def test_synchronization_modification_on_created_file(self):
        # Regression test: a file is created locally, then modification is
        # detected before first upload
        local = self.local_1
        workspace_path = Path(self.workspace_title)
        dao = self.engine_1.dao

        assert not local.exists("/")

        self.engine_1.start()
        self.wait_sync(wait_for_async=True)
        assert local.exists("/")
        self.engine_1.stop()
        # Let's create some documents on the client
        local.make_folder("/", "Folder")
        local.make_file("/Folder", "File.txt", content=b"Some content.")

        # First local scan (assuming the network is offline):
        self.queue_manager_1.suspend()
        self.queue_manager_1._disable = True
        self.engine_1.start()
        self.wait_sync(timeout=5, fail_if_timeout=False)
        children = dao.get_local_children(workspace_path)
        assert len(children) == 1
        assert children[0].pair_state == "locally_created"
        folder_children = dao.get_local_children(workspace_path / "Folder")
        assert len(folder_children) == 1
        assert folder_children[0].pair_state == "locally_created"

        # Wait a bit for file time stamps to increase enough: on most OS
        # the file modification time resolution is 1s
        time.sleep(OS_STAT_MTIME_RESOLUTION)

        # Let's modify it offline and wait for a bit
        local.update_content("/Folder/File.txt", content=b"Some content.")
        self.wait_sync(timeout=5, fail_if_timeout=False)
        # File has not been synchronized, it is still
        # in the locally_created state
        file_state = dao.get_state_from_local(workspace_path / "Folder/File.txt")
        assert file_state.pair_state == "locally_created"

        # Assume the computer is back online, the synchronization should occur
        # as if the document was just created and not trigger an update
        self.queue_manager_1._disable = False
        self.queue_manager_1.resume()
        self.wait_sync(wait_for_async=True)
        folder_state = dao.get_state_from_local(workspace_path / "Folder")
        assert folder_state.pair_state == "synchronized"
        file_state = dao.get_state_from_local(workspace_path / "Folder/File.txt")
        assert file_state.pair_state == "synchronized"

    def test_basic_synchronization(self):
        local = self.local_1
        remote = self.remote_document_client_1
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)

        # Let's create some document on the client and the server
        local.make_folder("/", "Folder 3")
        self.make_server_tree()

        # Launch ndrive and check synchronization
        self.wait_sync(wait_for_async=True)
        assert remote.exists("/Folder 3")
        assert local.exists("/Folder 1")
        assert local.exists("/Folder 2")
        assert local.exists("/File 5.txt")

    def test_docpair_export(self):
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)

        dao = self.engine_1.dao
        children = dao.get_local_children(Path("/"))
        assert children
        doc_pair = children[0]
        assert doc_pair.export()

    def test_synchronization_skip_errors(self):
        local = self.local_1
        dao = self.engine_1.dao

        assert not local.exists("/")

        # Perform first scan and sync
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)
        assert local.exists("/")
        self.engine_1.stop()

        # Let's create some documents on the client and the server
        local.make_folder("/", "Folder 3")
        self.make_server_tree()

        # Detect the files to synchronize but do not perform the
        # synchronization
        self.queue_manager_1.suspend()
        self.queue_manager_1._disable = True
        self.engine_1.start()
        self.wait_sync(wait_for_async=True, timeout=10, fail_if_timeout=False)

        children = dao.get_local_children(Path(self.workspace_title))
        assert len(children) == 4
        sorted_children = sorted(children, key=lambda x: x.local_path)
        assert sorted_children[0].remote_name == "File 5.txt"
        assert sorted_children[0].pair_state == "remotely_created"
        assert sorted_children[1].remote_name == "Folder 1"
        assert sorted_children[1].pair_state == "remotely_created"
        assert sorted_children[2].remote_name == "Folder 2"
        assert sorted_children[2].pair_state == "remotely_created"
        assert sorted_children[3].local_name == "Folder 3"
        assert sorted_children[3].pair_state == "locally_created"

        # Simulate synchronization errors
        file_5_state = sorted_children[0]
        folder_3_state = sorted_children[3]
        self.engine_1._local_watcher.increase_error(file_5_state, "TEST_FILE_ERROR")
        self.engine_1._local_watcher.increase_error(folder_3_state, "TEST_FILE_ERROR")

        # Run synchronization
        self.queue_manager_1._disable = False
        self.queue_manager_1.resume()
        # By default engine will not consider being syncCompleted
        # because of the temporary ignore dfile
        self.wait_sync(enforce_errors=False, fail_if_timeout=False)

        # All errors have been skipped, while the remaining docs have
        # been synchronized
        file_5_state = dao.get_normal_state_from_remote(file_5_state.remote_ref)
        assert file_5_state.pair_state == "remotely_created"
        folder_3_state = dao.get_state_from_local(folder_3_state.local_path)
        assert folder_3_state.pair_state == "locally_created"
        folder_1_state = dao.get_normal_state_from_remote(sorted_children[1].remote_ref)
        assert folder_1_state.pair_state == "synchronized"
        folder_2_state = dao.get_normal_state_from_remote(sorted_children[2].remote_ref)
        assert folder_2_state.pair_state == "synchronized"

        # Retry synchronization of pairs in error
        self.wait_sync()
        file_5_state = dao.get_normal_state_from_remote(file_5_state.remote_ref)
        assert file_5_state.pair_state == "synchronized"
        folder_3_state = dao.get_state_from_local(folder_3_state.local_path)
        assert folder_3_state.pair_state == "synchronized"

    def test_synchronization_give_up(self):
        # Override error threshold to 1 instead of 3
        test_error_threshold = 1
        self.queue_manager_1._error_threshold = test_error_threshold

        # Bound root but nothing is synchronized yet
        local = self.local_1
        dao = self.engine_1.dao
        workspace_path = Path(self.workspace_title)
        assert not local.exists("/")

        # Perform first scan and sync
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)
        assert local.exists("/")
        self.engine_1.stop()

        # Let's create some documents on the client and the server
        local.make_folder("/", "Folder 3")
        self.make_server_tree(deep=False)

        # Simulate a server failure on file download
        bad_remote = self.get_bad_remote()
        error = HTTPError(status=500, message="Mock download error")
        bad_remote.make_download_raise(error)

        # File is not synchronized but synchronization does not fail either,
        # errors are handled and queue manager has given up on them
        with patch.object(self.engine_1, "remote", new=bad_remote):
            self.engine_1.start()
            self.wait_sync(wait_for_async=True, timeout=60)
            states_in_error = dao.get_errors(limit=test_error_threshold)
            assert len(states_in_error) == 1
            children = dao.get_states_from_partial_local(workspace_path)
            assert len(children) == 4
            for state in children:
                if state.folderish:
                    assert state.pair_state == "synchronized"
                else:
                    assert state.pair_state != "synchronized"

        # Reset errors
        for state in states_in_error:
            dao.reset_error(state)

        # Verify that everything now gets synchronized
        self.wait_sync()
        assert not dao.get_errors(limit=test_error_threshold)
        children = dao.get_states_from_partial_local(workspace_path)
        assert len(children) == 4
        for child in children:
            assert child.pair_state == "synchronized"

    def test_synchronization_offline(self):
        # Bound root but nothing is synchronized yet
        local = self.local_1
        dao = self.engine_1.dao
        workspace_path = Path(self.workspace_title)
        assert not local.exists("/")

        # Perform first scan and sync
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)
        assert local.exists("/")
        self.engine_1.stop()

        # Let's create some documents on the client and the server
        local.make_folder("/", "Folder 3")
        self.make_server_tree(deep=False)

        # Find various ways to simulate a network failure
        bad_remote = self.get_bad_remote()
        errors = [
            ConnectionError("Mock connection error"),
            OSError("Mock socket error"),  # Old socket.error
            HTTPError(status=503, message="Mock"),
        ]

        engine_started = False
        with patch.object(self.engine_1, "remote", new=bad_remote):
            for error in errors:
                self.engine_1.remote.make_server_call_raise(error)
                if not engine_started:
                    self.engine_1.start()
                    engine_started = True

                # Synchronization doesn't occur but does not fail either.
                # - one 'locally_created' error is registered for Folder 3
                # - no states are inserted for the remote documents
                self.wait_sync(wait_for_async=True, fail_if_timeout=False)
                children = dao.get_states_from_partial_local(workspace_path)
                assert len(children) == 1
                assert children[0].pair_state != "synchronized"
                assert not self.engine_1.is_offline()

        # Starting here, the network is re-enable
        # Verify that everything now gets synchronized
        self.wait_sync(wait_for_async=True)
        assert not self.engine_1.is_offline()
        assert not dao.get_errors(limit=0)
        children = dao.get_states_from_partial_local(workspace_path)
        assert len(children) == 4
        for state in children:
            assert state.pair_state == "synchronized"

    def test_create_content_in_readonly_area(self):
        dao = self.engine_1.dao
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)

        # Let's create a subfolder of the main readonly folder
        local = LocalTest(self.local_nxdrive_folder_1)
        local.make_folder("/", "Folder 3")
        local.make_file("/Folder 3", "File 1.txt", content=b"Some content.")
        local.make_folder("/Folder 3", "Sub Folder 1")
        local.make_file(
            "/Folder 3/Sub Folder 1", "File 2.txt", content=b"Some other content."
        )
        self.wait_sync()

        # States have been created for the subfolder and its content,
        # subfolder is marked as unsynchronized
        good_states = ("locally_created", "unsynchronized")
        states = dao.get_states_from_partial_local(ROOT)
        assert len(states) == 6
        sorted_states = sorted(states, key=lambda x: x.local_path)
        assert sorted_states[0].local_name == ""
        assert sorted_states[0].pair_state == "synchronized"
        assert sorted_states[1].local_name == "Folder 3"
        assert sorted_states[1].pair_state == "unsynchronized"
        assert sorted_states[2].local_name == "File 1.txt"
        assert sorted_states[2].pair_state in good_states
        assert sorted_states[3].local_name == "Sub Folder 1"
        assert sorted_states[3].pair_state in good_states
        assert sorted_states[4].local_name == "File 2.txt"
        assert sorted_states[4].pair_state in good_states
        assert sorted_states[5].local_name == self.workspace_title
        assert sorted_states[5].pair_state == "synchronized"

        # Let's create a file in the main readonly folder
        local.make_file("/", "A file in a readonly folder.txt", content=b"Some Content")
        self.wait_sync()

        # A state has been created, marked as unsynchronized
        # Other states are unchanged
        states = dao.get_states_from_partial_local(ROOT)
        assert len(states) == 7
        sorted_states = sorted(states, key=lambda x: x.local_path)
        assert sorted_states[0].local_name == ""
        assert sorted_states[0].pair_state == "synchronized"
        assert sorted_states[1].local_name == "A file in a readonly folder.txt"
        assert sorted_states[1].pair_state == "unsynchronized"
        assert sorted_states[2].local_name == "Folder 3"
        assert sorted_states[2].pair_state == "unsynchronized"
        assert sorted_states[3].local_name == "File 1.txt"
        assert sorted_states[3].pair_state in good_states
        assert sorted_states[4].local_name == "Sub Folder 1"
        assert sorted_states[4].pair_state in good_states
        assert sorted_states[5].local_name == "File 2.txt"
        assert sorted_states[5].pair_state in good_states
        assert sorted_states[6].local_name == self.workspace_title
        assert sorted_states[6].pair_state == "synchronized"

        # Let's create a file and a folder in a folder on which the Write
        # permission has been removed. Thanks to NXP-13119, this permission
        # change will be detected server-side, thus fetched by the client
        # in the remote change summary, and the remote_can_create_child flag
        # on which the synchronizer relies to check if creation is allowed
        # will be set to False and no attempt to create the remote file
        # will be made.
        # States will be marked as unsynchronized.

        workspace_path = Path(self.workspace_title)
        # Create local folder and synchronize it remotely
        local = self.local_1
        local.make_folder("/", "Readonly folder")
        self.wait_sync()

        remote = self.remote_document_client_1
        assert remote.exists("/Readonly folder")

        # Check remote_can_create_child flag in pair state
        readonly_folder_state = dao.get_state_from_local(
            workspace_path / "Readonly folder"
        )
        assert readonly_folder_state.remote_can_create_child

        # Wait again for synchronization to detect remote folder creation
        # triggered by last synchronization and make sure we get a clean
        # state at next change summary
        self.wait_sync(wait_for_async=True)
        readonly_folder_state = dao.get_state_from_local(
            workspace_path / "Readonly folder"
        )
        assert readonly_folder_state.remote_can_create_child

        # Set remote folder as readonly for test user
        readonly_folder_path = f"{self.ws.path}/Readonly folder"
        self._set_read_permission(self.user_1, readonly_folder_path, True)
        self.root_remote.block_inheritance(readonly_folder_path, overwrite=False)

        # Wait to make sure permission change is detected.
        self.wait_sync(wait_for_async=True)
        # Re-fetch folder state and check remote_can_create_child
        # flag has been updated
        readonly_folder_state = dao.get_state_from_local(
            workspace_path / "Readonly folder"
        )
        assert not readonly_folder_state.remote_can_create_child

        # Try to create a local file and folder in the readonly folder,
        # they should not be created remotely and be marked as unsynchronized.
        local.make_file(
            "/Readonly folder", "File in readonly folder", content=b"File content"
        )
        local.make_folder("/Readonly folder", "Folder in readonly folder")
        self.wait_sync()
        assert not remote.exists("/Readonly folder/File in readonly folder")
        assert not remote.exists("/Readonly folder/Folder in readonly folder")

        states = dao.get_states_from_partial_local(
            workspace_path / "Readonly folder", strict=False
        )
        assert len(states) == 3
        sorted_states = sorted(states, key=lambda x: x.local_path)
        assert sorted_states[0].local_name == "Readonly folder"
        assert sorted_states[0].pair_state == "synchronized"
        assert sorted_states[1].local_name == "File in readonly folder"
        assert sorted_states[1].pair_state == "unsynchronized"
        assert sorted_states[2].local_name == "Folder in readonly folder"
        assert sorted_states[2].pair_state == "unsynchronized"

    def test_synchronize_special_filenames(self):
        local = self.local_1
        remote = self.remote_document_client_1
        self.engine_1.start()

        # Create a remote folder with a weird name
        folder = remote.make_folder(self.workspace, 'Folder with chars: / \\ * < > ? "')
        characters = "- - - - - - - -"
        foldername = f"Folder with chars{characters}"

        self.wait_sync(wait_for_async=True)
        folder_names = [i.name for i in local.get_children_info("/")]
        assert folder_names == [foldername]

        # Create a remote file with a weird name
        file = remote.make_file(
            folder, 'File with chars: / \\ * < > ? ".txt', content=b"some content"
        )
        filename = f"File with chars{characters}.txt"

        self.wait_sync(wait_for_async=True)
        file_names = [
            i.name
            for i in local.get_children_info(local.get_children_info("/")[0].path)
        ]
        assert file_names == [filename]

        # Update a remote file with a weird name (NXDRIVE-286)
        remote.update(file, properties={"note:note": "new content"})
        self.wait_sync(wait_for_async=True, enforce_errors=False)
        assert local.get_content(f"/{foldername}/{filename}") == b"new content"
        file_state = self.get_dao_state_from_engine_1(f"{foldername}/{filename}")
        assert file_state.pair_state == "synchronized"
        assert file_state.local_digest == file_state.remote_digest

        # Update note title with a weird name
        remote.update(
            file, properties={"dc:title": 'File with chars: / \\ * < > ? " - 2'}
        )
        filename = f"File with chars{characters} - 2.txt"
        self.wait_sync(wait_for_async=True, enforce_errors=False)
        file_names = [
            i.name
            for i in local.get_children_info(local.get_children_info("/")[0].path)
        ]
        assert file_names == [filename]

        # Update note title changing the case (NXRIVE-532)
        remote.update(
            file, properties={"dc:title": 'file with chars: / \\ * < > ? " - 2'}
        )
        filename = f"file with chars{characters} - 2.txt"
        self.wait_sync(wait_for_async=True, enforce_errors=False)
        file_names = [
            i.name
            for i in local.get_children_info(local.get_children_info("/")[0].path)
        ]
        assert file_names == [filename]

    def test_synchronize_error_remote(self):
        path = Path(f"/{self.workspace_title}") / "test.odt"
        remote = self.remote_document_client_1
        dao = self.engine_1.dao

        bad_remote = self.get_bad_remote()
        error = HTTPError(status=400, message="Mock")
        bad_remote.make_download_raise(error)

        with patch.object(self.engine_1, "remote", new=bad_remote):
            remote.make_file("/", "test.odt", content=b"Some content.")

            self.engine_1.start()
            self.wait_sync(wait_for_async=True)
            self.engine_1.stop()

            pair = dao.get_state_from_local(path)
            assert pair is not None
            assert pair.error_count
            assert pair.pair_state == "remotely_created"

            self.engine_1.start()
            self.wait_sync()
            pair = dao.get_state_from_local(path)
            assert pair.error_count == 4
            assert pair.pair_state == "remotely_created"

        # Requeue errors
        self.engine_1.retry_pair(pair.id)
        self.wait_sync()
        pair = dao.get_state_from_local(path)
        assert not pair.error_count
        assert pair.pair_state == "synchronized"

    def test_synchronize_deleted_blob(self):
        local = self.local_1
        remote = self.remote_document_client_1
        self.engine_1.start()

        # Create a doc with a blob in the remote root workspace
        # then synchronize
        file_path = self.location / "resources" / "files" / "testFile.odt"
        remote.make_file("/", file_path.name, file_path=file_path)

        self.wait_sync(wait_for_async=True)
        assert local.exists(f"/{file_path.name}")

        # Delete the blob from the remote doc then synchronize
        remote.delete_content(f"/{file_path.name}")

        self.wait_sync(wait_for_async=True)
        assert not local.exists(f"/{file_path.name}")

    def test_synchronize_deletion(self):
        local = self.local_1
        remote = self.remote_document_client_1
        self.engine_1.start()

        # Create a remote folder with 2 children then synchronize
        remote.make_folder("/", "Remote folder")
        remote.make_file(
            "/Remote folder", "Remote file 1.odt", content=b"Some content."
        )
        remote.make_file(
            "/Remote folder", "Remote file 2.odt", content=b"Other content."
        )

        self.wait_sync(wait_for_async=True)
        assert local.exists("/Remote folder")
        assert local.exists("/Remote folder/Remote file 1.odt")
        assert local.exists("/Remote folder/Remote file 2.odt")

        # Delete remote folder then synchronize
        remote.delete("/Remote folder")

        self.wait_sync(wait_for_async=True)
        assert not local.exists("/Remote folder")
        assert not local.exists("/Remote folder/Remote file 1.odt")
        assert not local.exists("/Remote folder/Remote file 2.odt")

        # Create a local folder with 2 children then synchronize
        local.make_folder("/", "Local folder")
        local.make_file("/Local folder", "Local file 1.odt", content=b"Some content.")
        local.make_file("/Local folder", "Local file 2.odt", content=b"Other content.")

        self.wait_sync()
        assert remote.exists("/Local folder")
        assert remote.exists("/Local folder/Local file 1.odt")
        assert remote.exists("/Local folder/Local file 2.odt")

        # Delete local folder then synchronize
        time.sleep(OS_STAT_MTIME_RESOLUTION)
        local.delete("/Local folder")

        # Since errors are generated by the deletion events sent by Watchdog
        # for the folder children under UNIX, don't enforce errors
        self.wait_sync(enforce_errors=WINDOWS)
        assert not remote.exists("/Local folder")
        # Wait for async completion as recursive deletion of children is done
        # by the BulkLifeCycleChangeListener which is asynchronous
        self.wait()
        assert not remote.exists("/Local folder/Local file 1.odt")
        assert not remote.exists("/Local folder/Local file 2.odt")

    def test_synchronize_windows_foldername_endswith_space(self):
        """
        Use nuxeodrive.CreateFolder API to make a folder directly
        under the workspace "trial ". Verify if the DS client downloads
        the folder and trims the space at the end
        """
        remote = self.remote_document_client_1
        target = remote.make_folder("/", "trial ")
        local = self.local_root_client_1
        remote.make_file(target, "aFile.txt", content=b"File A Content")
        remote.make_file(target, "bFile.txt", content=b"File B Content")
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)
        assert local.exists(f"/{self.workspace_title}")
        if WINDOWS:
            assert local.exists(f"/{self.workspace_title}/trial/")
            assert local.exists(f"/{self.workspace_title}/trial/aFile.txt")
            assert local.exists(f"/{self.workspace_title}/trial/bFile.txt")
        else:
            assert local.exists(f"/{self.workspace_title}/trial /")
            assert local.exists(f"/{self.workspace_title}/trial /aFile.txt")
            assert local.exists(f"/{self.workspace_title}/trial /bFile.txt")

    def test_409_conflict(self):
        """
        Test concurrent upload with files having the same first characters.
        """

        remote = self.remote_document_client_1
        local = self.local_1
        engine = self.engine_1

        engine.start()
        self.wait_sync(wait_for_async=True)
        assert local.exists("/")

        def _raise_for_second_file_only(*args, **kwargs):
            return kwargs.get("filename").endswith("2.txt")

        # Simulate a server conflict on file upload
        bad_remote = self.get_bad_remote()
        error = Conflict(message="Mock Conflict")
        bad_remote.make_upload_raise(error)
        bad_remote.raise_on = _raise_for_second_file_only

        with patch.object(self.engine_1, "remote", new=bad_remote):
            # Create 2 files locally
            base = "A" * 40
            file1 = base + "1.txt"
            file2 = base + "2.txt"
            local.make_file("/", file1, content=b"foo")
            local.make_file("/", file2, content=b"bar")

            self.wait_sync(fail_if_timeout=False)

            # Checks
            assert engine.dao.queue_manager.get_errors_count() == 1
            children = remote.get_children_info(self.workspace)
            assert len(children) == 1
            assert children[0].name == file1

        # Starting here, default behavior is restored
        self.wait_sync()

        # Checks
        children = remote.get_children_info(self.workspace)
        assert len(children) == 2
        assert children[0].name == file1
        assert children[1].name == file2

    def test_416_range_past_eof(self):
        """
        Test wrong bytes range during download.
        """

        remote = self.remote_document_client_1
        local = self.local_1
        engine = self.engine_1

        engine.start()
        self.wait_sync(wait_for_async=True)
        assert local.exists("/")

        remote.make_file("/", "test.bin", content=b"42")

        # Simulate a requested range not satisfiable on file download
        bad_remote = self.get_bad_remote()
        error = HTTPError(status=416, message="Mock Requested Range Not Satisfiable")
        bad_remote.make_download_raise(error)

        with patch.object(self.engine_1, "remote", new=bad_remote):
            self.wait_sync(fail_if_timeout=False)
            # Checks
            assert engine.dao.queue_manager.get_errors_count() == 1

        # Starting here, default behavior is restored
        self.wait_sync()

        # Checks
        assert not engine.dao.get_errors()
        assert local.exists("/test.bin")

    def test_local_modify_offline(self):
        local = self.local_1
        engine = self.engine_1

        engine.start()
        self.wait_sync(wait_for_async=True)

        local.make_folder("/", "Test")
        local.make_file("/Test", "Test.txt", content=b"Some content")
        self.wait_sync()

        engine.stop()
        local.update_content("/Test/Test.txt", b"Another content")

        engine.start()
        self.wait_sync()
        assert not engine.dao.get_errors()

    def test_unsynchronize_accentued_document(self):
        remote = self.remote_document_client_1
        local = self.local_1
        engine = self.engine_1
        engine.start()

        # Create the folder
        root_name = "Été indian"
        root = remote.make_folder(self.workspace, root_name)
        self.wait_sync(wait_for_async=True)
        assert local.exists("/" + root_name)

        # Remove the folder
        remote.delete(root)
        self.wait_sync(wait_for_async=True)
        assert not local.exists("/" + root_name)

    def test_synchronize_document_with_pattern(self):
        """
        Simple test to ensure there is no issue with files like "$AAA000$.doc".
        Related to NXDRIVE-1287.
        """
        name = "$NAB184$.doc"
        self.remote_document_client_1.make_file("/", name, content=b"42")
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)
        assert self.local_1.exists(f"/{name}")

    def test_rename_duplicates(self):
        remote = self.remote_document_client_1
        local = self.local_1
        engine = self.engine_1

        # Create 7 files with the same name
        name = "Congés 2016 / 2017.txt"
        name_expected = safe_filename(name)
        for _ in range(7):
            remote.make_file("/", name, content=b"42")

        # Start sync
        engine.start()
        self.wait_sync(wait_for_async=True)

        # Check that one file exists, and engine has 6 errors
        assert local.exists(f"/{name_expected}")
        assert len(local.get_children_info("/")) == 1
        assert len(engine.dao.get_errors(limit=0)) == 6

        # Rename all remote documents with unique names
        ref = local.get_remote_id("/")
        children = self.remote_1.get_fs_children(ref)
        assert len(children) == 7
        remote_files = set()
        for child in children:
            new_name = f"{child.uid.split('#')[-1]}-{safe_filename(child.name)}"
            remote_files.add(new_name)
            remote.execute(command="NuxeoDrive.Rename", id=child.uid, name=new_name)

        self.wait_sync(wait_for_async=True)

        children = self.remote_1.get_fs_children(ref)
        assert len(children) == 7
        # Check that the 7 files exist locally and that there are no errors
        local_children = local.get_children_info("/")
        assert len(local_children) == 7
        local_files = {child.name for child in local_children}
        assert not engine.dao.get_errors(limit=0)
        assert remote_files == local_files

    def test_local_creation_copying_from_sibling(self):
        """Test a local file creation when checking for an already synced file on the HDD."""

        remote = self.remote_document_client_1
        local = self.local_1
        engine = self.engine_1

        engine.start()
        self.wait_sync(wait_for_async=True)

        # Create a remote folder and a file inside it
        contents = b"1234567890" * 42 * 42
        remote.make_folder("/", "a folder")
        remote.make_file("/a folder", "file1.bin", content=contents)
        self.wait_sync(wait_for_async=True)

        def stream_content(*args, **kwargs):
            """Called by Processor._download_content(). We are testing that this method is never called."""
            assert 0, "Should not be called!"

        # Create another files with the same contents and check that the remote client downloads nothing
        with patch.object(self.engine_1.remote, "stream_content", new=stream_content):
            remote.make_file("/a folder", "file2.bin", content=contents)
            remote.make_file("/", "file3.bin", content=contents)
            self.wait_sync(wait_for_async=True)

        # Checks
        assert not engine.dao.queue_manager.get_errors_count()
        for client in (remote, local):
            assert client.exists("/a folder/file1.bin")
            assert client.exists("/a folder/file2.bin")
            assert client.exists("/file3.bin")


class TestSynchronization2(TwoUsersTest):
    def test_conflict_detection(self):
        # Fetch the workspace sync root
        local = self.local_1
        dao = self.engine_1.dao
        workspace_path = Path(self.workspace_title)
        self.engine_1.start()
        self.wait_sync(wait_for_async=True)
        assert local.exists("/")

        # Let's create a file on the client and synchronize it.
        local_path = local.make_file("/", "Some File.doc", content=b"Original content.")
        self.wait_sync()

        # Let's modify it concurrently but with the same content (digest)
        self.engine_1.suspend()
        time.sleep(OS_STAT_MTIME_RESOLUTION)
        local.update_content(local_path, b"Same new content.")

        remote_2 = self.remote_document_client_2
        remote_2.update_content("/Some File.doc", b"Same new content.")
        self.engine_1.resume()

        # Let's synchronize and check the conflict handling: automatic
        # resolution will work for this case
        self.wait_sync(wait_for_async=True)
        assert not self.engine_1.get_conflicts()
        children = dao.get_states_from_partial_local(workspace_path)
        assert len(children) == 1
        assert children[0].pair_state == "synchronized"

        local_children = local.get_children_info("/")
        assert len(local_children) == 1
        assert local_children[0].name == "Some File.doc"
        assert local.get_content(local_path) == b"Same new content."
        remote_1 = self.remote_document_client_1
        remote_children = remote_1.get_children_info(self.workspace)
        assert len(remote_children) == 1
        assert remote_children[0].get_blob("file:content").name == "Some File.doc"
        assert remote_1.get_content("/Some File.doc") == b"Same new content."

        # Let's trigger another conflict that cannot be resolved
        # automatically:
        self.engine_1.suspend()
        time.sleep(OS_STAT_MTIME_RESOLUTION)
        local.update_content(local_path, b"Local new content.")

        remote_2.update_content("/Some File.doc", b"Remote new content.")
        self.engine_1.resume()

        # Let's synchronize and check the conflict handling
        self.wait_sync(wait_for_async=True)
        assert len(self.engine_1.get_conflicts()) == 1
        children = dao.get_states_from_partial_local(workspace_path)
        assert len(children) == 1
        assert children[0].pair_state == "conflicted"

        local_children = local.get_children_info("/")
        assert len(local_children) == 1
        assert local_children[0].name == "Some File.doc"
        assert local.get_content(local_path) == b"Local new content."
        remote_children = remote_1.get_children_info(self.workspace)
        assert len(remote_children) == 1
        assert remote_children[0].get_blob("file:content").name == "Some File.doc"
        assert remote_1.get_content("/Some File.doc") == b"Remote new content."

    def test_rename_and_create_same_folder_not_running(self):
        """
        NXDRIVE-668: Fix upload issue when renaming a folder and creating
        a folder with the same name while Drive client is not running:

        IntegrityError: UNIQUE constraint failed:
                        States.remote_ref, States.local_path
        """

        remote = self.remote_document_client_1
        local_1 = self.local_1
        local_2 = self.local_2
        self.engine_1.start()
        self.engine_2.start()
        self.wait_sync(wait_for_async=True, wait_for_engine_2=True)

        # First, create initial folders and files
        folder = remote.make_folder("/", "Folder01")
        remote.make_folder("/Folder01", "subfolder01")
        remote.make_file("/Folder01/subfolder01", "File01.txt", content=b"42")
        self.wait_sync(wait_for_async=True, wait_for_engine_2=True)
        assert remote.exists("/Folder01/subfolder01")
        assert remote.exists("/Folder01/subfolder01/File01.txt")
        assert local_1.exists("/Folder01/subfolder01")
        assert local_1.exists("/Folder01/subfolder01/File01.txt")
        assert local_2.exists("/Folder01/subfolder01")
        assert local_2.exists("/Folder01/subfolder01/File01.txt")

        # Stop clients and make the local changes on a folder
        self.engine_1.stop()
        self.engine_2.stop()
        local_2.rename("/Folder01/subfolder01", "subfolder02")
        local_2.make_folder("/Folder01", "subfolder01")
        local_2.make_file("/Folder01/subfolder01", "File02.txt", content=b"42.42")
        self.engine_1.start()
        self.engine_2.start()
        self.wait_sync(wait_for_async=True, wait_for_engine_2=True)

        # Check client 2
        assert local_2.exists("/Folder01/subfolder02")
        assert local_2.exists("/Folder01/subfolder02/File01.txt")
        assert local_2.get_content("/Folder01/subfolder02/File01.txt") == b"42"
        assert local_2.exists("/Folder01/subfolder01")
        assert local_2.exists("/Folder01/subfolder01/File02.txt")
        assert local_2.get_content("/Folder01/subfolder01/File02.txt") == b"42.42"

        # Check server
        children = remote.get_children_info(folder)
        assert len(children) == 2
        assert children[0].name == "subfolder01"
        child = remote.get_children_info(children[0].uid)
        assert child[0].name == "File02.txt"
        assert remote.get_content(child[0]) == b"42.42"
        assert children[1].name == "subfolder02"
        child = remote.get_children_info(children[1].uid)
        assert child[0].name == "File01.txt"
        assert remote.get_content(child[0]) == b"42"

        # Check client 1
        assert local_1.exists("/Folder01/subfolder02")
        """
        # TODO NXDRIVE-777: uncomment when issue is fixed
        assert local_1.exists('/Folder01/subfolder02/File01.txt')
        assert local_1.get_content('/Folder01/subfolder02/File01.txt') == b'42'
        # TODO NXDRIVE-769: uncomment when deduplication issue is fixed
        assert local_1.exists('/Folder01/subfolder01')
        assert local_1.exists('/Folder01/subfolder01/File02.txt')
        assert local_1.get_content(
            '/Folder01/subfolder01/File02.txt') == b'42.42'
        """

    def test_rename_and_create_same_file_not_running(self):
        """
        Same as `test_rename_and_create_same_folder_not_running`
        but with changes made on a file.
        """

        remote = self.remote_document_client_1
        local_1 = self.local_1
        local_2 = self.local_2
        self.engine_1.start()
        self.engine_2.start()
        self.wait_sync(wait_for_async=True, wait_for_engine_2=True)

        # First, create initial folders and files
        folder = remote.make_folder("/", "Folder01")
        remote.make_file("/Folder01", "File01.txt", content=b"42")
        self.wait_sync(wait_for_async=True, wait_for_engine_2=True)
        assert remote.exists("/Folder01/File01.txt")
        assert local_1.exists("/Folder01/File01.txt")
        assert local_2.exists("/Folder01/File01.txt")

        # Stop clients and make the local changes on a file
        self.engine_1.stop()
        self.engine_2.stop()
        local_2.rename("/Folder01/File01.txt", "File02.txt")
        # Create a new file with the same name and content as
        # the previously renamed file
        local_2.make_file("/Folder01", "File01.txt", content=b"42")
        self.engine_1.start()
        self.engine_2.start()
        self.wait_sync(wait_for_async=True, wait_for_engine_2=True)

        # Check client 2
        assert local_2.exists("/Folder01/File02.txt")
        assert local_2.get_content("/Folder01/File02.txt") == b"42"
        assert local_2.exists("/Folder01/File01.txt")
        assert local_2.get_content("/Folder01/File01.txt") == b"42"

        # Check server
        children = remote.get_children_info(folder)
        assert len(children) == 2
        assert children[0].name == "File01.txt"
        assert remote.get_content(children[0]) == b"42"
        assert children[1].name == "File02.txt"
        assert remote.get_content(children[1]) == b"42"

        # Check client 1
        assert local_1.exists("/Folder01/File02.txt")
        assert local_1.get_content("/Folder01/File02.txt") == b"42"
        # TODO NXDRIVE-769: uncomment when deduplication issue is fixed
        # assert local_1.exists('/Folder01/File01.txt')
        # assert local_1.get_content('/Folder01/File01.txt') == b'42'

        # Stop clients and make the local changes on a file
        self.engine_1.stop()
        self.engine_2.stop()
        local_2.rename("/Folder01/File01.txt", "File03.txt")
        # Create a new file with the same name as the previously renamed
        # file but a different content
        local_2.make_file("/Folder01", "File01.txt", content=b"42.42")
        self.engine_1.start()
        self.engine_2.start()
        self.wait_sync(wait_for_async=True)

        # Check client 2
        assert local_2.exists("/Folder01/File03.txt")
        assert local_2.get_content("/Folder01/File03.txt") == b"42"
        assert local_2.exists("/Folder01/File02.txt")
        assert local_2.get_content("/Folder01/File02.txt") == b"42"
        assert local_2.exists("/Folder01/File01.txt")
        assert local_2.get_content("/Folder01/File01.txt") == b"42.42"

        # Check server
        children = remote.get_children_info(folder)
        assert len(children) == 3
        assert children[0].name == "File01.txt"
        assert remote.get_content(children[0]) == b"42.42"
        assert children[1].name == "File02.txt"
        assert remote.get_content(children[1]) == b"42"
        assert children[2].name == "File03.txt"
        assert remote.get_content(children[2]) == b"42"

        # Check client 1
        assert local_1.exists("/Folder01/File03.txt")
        assert local_1.get_content("/Folder01/File03.txt") == b"42"
        assert local_1.exists("/Folder01/File02.txt")
        assert local_1.get_content("/Folder01/File02.txt") == b"42"
        assert local_1.exists("/Folder01/File01.txt")
        assert local_1.get_content("/Folder01/File01.txt") == b"42.42"
